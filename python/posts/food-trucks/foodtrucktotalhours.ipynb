{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80b8f1c8-380c-434a-af02-871c1d093acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: UCLATicketCountSheet_61223.xlsx. Please check the file path or upload the file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to extract and combine food truck data with a sheet range\n",
    "def extract_and_combine_foodtruck_data(file_path, sheet_start=None, sheet_end=None):\n",
    "    excel_file = pd.ExcelFile(file_path)\n",
    "    combined_data = {}\n",
    "\n",
    "    # Determine the sheets to process based on the range\n",
    "    sheets_to_process = excel_file.sheet_names[sheet_start:sheet_end]\n",
    "\n",
    "    for sheet in sheets_to_process:\n",
    "        # Read the current sheet\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet)\n",
    "        \n",
    "        # Extract the second column where times and food trucks are stored\n",
    "        second_column = df.iloc[:, 1]\n",
    "        current_time = None\n",
    "        \n",
    "        for i, value in enumerate(second_column):\n",
    "            if isinstance(value, str) and \"-\" in value and \":\" in value:\n",
    "                # Detect a time interval\n",
    "                current_time = value.strip()\n",
    "                if current_time not in combined_data:\n",
    "                    combined_data[current_time] = []\n",
    "            elif value == \"Name/Meal Period\":\n",
    "                # Skip this row\n",
    "                continue\n",
    "            elif current_time and value == \"Total:\":\n",
    "                # Stop collecting for the current time interval\n",
    "                current_time = None\n",
    "            elif current_time and pd.notna(value):\n",
    "                # Add food truck names under the current time interval\n",
    "                combined_data[current_time].append(value)\n",
    "    \n",
    "    # Convert the combined_data dictionary into a DataFrame\n",
    "    combined_df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in combined_data.items()]))\n",
    "    return combined_df\n",
    "\n",
    "# Apply the function to your Excel file\n",
    "import os\n",
    "\n",
    "file_path = \"UCLATicketCountSheet_61223.xlsx\"  # Replace with the path to your Excel file\n",
    "sheet_start = 67  # Starting index (0-based, so 4 corresponds to sheet 5)\n",
    "sheet_end = 380   # Ending index (non-inclusive, so 10 corresponds to sheet 10)\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    combined_foodtruck_data = extract_and_combine_foodtruck_data(\"UCLATicketCountSheet_61223.xlsx\", sheet_start, sheet_end)\n",
    "    # Save the result to a CSV file\n",
    "    combined_foodtruck_data.to_csv(\"combined_foodtruck_schedule.csv\", index=False)\n",
    "    print(combined_foodtruck_data)\n",
    "else:\n",
    "    print(f\"File not found: {file_path}. Please check the file path or upload the file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312767b3-d917-4e67-935e-25a8cac515e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'combined_foodtruck_schedule.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load dataset\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m combined_foodtruck_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcombined_foodtruck_schedule.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# get rid of entries with asterisk b/c * indicates cancelled/did not show\u001b[39;00m\n\u001b[1;32m      7\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m combined_foodtruck_data\u001b[38;5;241m.\u001b[39mapplymap(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mnan \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(x) \u001b[38;5;28;01melse\u001b[39;00m x)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'combined_foodtruck_schedule.csv'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "combined_foodtruck_data = pd.read_csv(\"combined_foodtruck_schedule.csv\")\n",
    "\n",
    "# get rid of entries with asterisk b/c * indicates cancelled/did not show\n",
    "combined_df = combined_foodtruck_data.applymap(lambda x: np.nan if '*' in str(x) else x)\n",
    "\n",
    "def rename_food_trucks(df):\n",
    "    replacements = [\n",
    "        (r'8E8', '8E8 Thai Street Food'),\n",
    "        (r'Belly', \"Belly's Sliders\"),\n",
    "        (r'Smile', 'Smile Hot Dog'),\n",
    "        (r'Aloha', 'Aloha Fridays'),\n",
    "        (r'Bittie|bittie', 'Bittie Bitez'),\n",
    "        (r'Bollywwood Kitchen|Bolywood Kitchen|Bollywood', 'Bollywood Kitchen'),\n",
    "        (r'Cerda', 'Cerda Vega'),\n",
    "        (r'Deli ', 'Deli Doctor '),\n",
    "        (r'grain|Grain', 'Flaming Grain'),\n",
    "        (r'Habibi', 'Habibi Shack'),\n",
    "        (r'Heritage', 'Heritage'),\n",
    "        (r'Aus|Autyn', \"Austyn's Burgers\"),\n",
    "        (r'Kogi', 'Kogi'),\n",
    "        (r'Yuna', \"Yuna's Bob\"),\n",
    "        (r'Wafl', 'Wafl'),\n",
    "        (r'Venice', 'Venice Gelato'),\n",
    "        (r'Uncle|Unle', \"Uncle Al's\"),\n",
    "        (r'TrapiYaki', 'Trapiyaki'),\n",
    "        (r'Tokyo', 'Tokyo Style'),\n",
    "        (r'Cocina', 'Thai Mex Cocina'),\n",
    "        (r'Taste', 'Taste Collective Burger'),\n",
    "        (r'Cartel', 'Cartel Tacos'),\n",
    "        (r'Sweet', 'Sweets on Wheels'),\n",
    "        (r'Sugo', 'Sugo Italiano'),\n",
    "        (r'Bye', 'StopBye Café'),\n",
    "        (r'Stout', 'Stout Burgers'),\n",
    "        (r'europa|Europa', 'Dulce Europa'),\n",
    "        (r'Savage', 'Savage Tacos'),\n",
    "        (r'Poutine', 'Poutine Brothers'),\n",
    "        (r'Pinch', 'Pinch of Flavor'),\n",
    "        (r'Philly|Phily', \"Philly Jay's\"),\n",
    "        (r'Pacifico', 'Pacifico Charbroiled'),\n",
    "        (r'Original', 'Original Herbivore'),\n",
    "        (r'Paradise', 'Paradise'),\n",
    "        (r'ML E', 'ML Eats'),\n",
    "        (r'Manna', 'Manna from Heaven'),\n",
    "        (r'Perro', 'Perro'),\n",
    "        (r'Kal', 'Kalamaki Greek'),\n",
    "        (r'Fusion|fusion', 'Go Fusion'),\n",
    "        (r'Cream', 'Creamy Boys'),\n",
    "        (r'Dina', \"Dina's Dumplings\"),\n",
    "        (r'Bison', 'Bison Burger'),\n",
    "        (r'Bunz', 'Bunz Gourmet'),\n",
    "        (r'Chicken|chicken', 'Flaming Hot Chicken'),\n",
    "        (r'Flaming Hot|Flamng Hot', 'Flaming Hot Chicken'),\n",
    "        (r'\\*Streets of Vietnam', 'Streets of Vietnam'),\n",
    "        (r'Baby|Bbay', \"Baby's Burgers\"),\n",
    "        (r'Café Vietname', 'Café Vietnam')\n",
    "    ]\n",
    "    \n",
    "    def replace_if_contains(text):\n",
    "        for pattern, replacement in replacements:\n",
    "            if pd.notna(text) and pd.Series(text).str.contains(pattern, regex=True).any():\n",
    "                return replacement  # Replace the entire string\n",
    "        return text  # Keep original if no match\n",
    "\n",
    "    return df.applymap(replace_if_contains)\n",
    "\n",
    "cleaned_df = rename_food_trucks(combined_df)\n",
    "\n",
    "# Reshape the data: Count occurrences of each vendor for each time slot\n",
    "formatted_data = {}\n",
    "\n",
    "# Iterate through each time slot column and count occurrences of each vendor\n",
    "for col in cleaned_df.columns:\n",
    "    vendor_counts = cleaned_df[col].value_counts()\n",
    "    formatted_data[col] = vendor_counts\n",
    "\n",
    "# Convert dictionary to a DataFrame and fill missing values with 0\n",
    "counts_df = pd.DataFrame(formatted_data).fillna(0).astype(int)\n",
    "\n",
    "# Save the cleaned data\n",
    "counts_df.to_csv(\"counts.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839351f0-0887-4b76-895f-8ee6b16443bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    index  11:00am - 3pm  5:00pm - 9pm  \\\n",
      "0                    8E8 Thai Street Food          124.0         140.0   \n",
      "1                           Aloha Fridays           88.0         100.0   \n",
      "2                             Asian (TBD)            0.0           0.0   \n",
      "3                        Austyn's Burgers           28.0          48.0   \n",
      "4                          Baby's Burgers           32.0          28.0   \n",
      "5                         Belly's Sliders           44.0          28.0   \n",
      "6                            Bison Burger           72.0          68.0   \n",
      "7                            Bittie Bitez            8.0           4.0   \n",
      "8                       Bollywood Kitchen           72.0          92.0   \n",
      "9                            Bunz Gourmet            8.0          12.0   \n",
      "10                           Café Vietnam           32.0          48.0   \n",
      "11                           Cartel Tacos          144.0          92.0   \n",
      "12                             Cerda Vega          104.0         108.0   \n",
      "13                            Creamy Boys            8.0          20.0   \n",
      "14                           Deli Doctor             0.0           8.0   \n",
      "15  Delicias El Torito Mexican Food Truck            0.0           0.0   \n",
      "16                       Dina's Dumplings          124.0         116.0   \n",
      "17                           Dulce Europa           32.0          60.0   \n",
      "18                          Flaming Grain          116.0          60.0   \n",
      "19                    Flaming Hot Chicken           76.0          92.0   \n",
      "20                             Food Truck            0.0           0.0   \n",
      "21                              Go Fusion           64.0          72.0   \n",
      "22                    Good Eats and Vibes            0.0           0.0   \n",
      "23                           Habibi Shack           44.0         104.0   \n",
      "24                               Heritage           24.0           8.0   \n",
      "25                          Kabab Express            0.0           0.0   \n",
      "26                         Kalamaki Greek           76.0          92.0   \n",
      "27                                   Kogi           28.0          52.0   \n",
      "28                           Lockdown BBQ            0.0           0.0   \n",
      "29                                ML Eats            0.0           0.0   \n",
      "30                      Manna from Heaven            0.0           0.0   \n",
      "31                          Messi Burgers            0.0           0.0   \n",
      "32                                Mikhuna            0.0           0.0   \n",
      "33                          Ohana Hibachi            0.0           0.0   \n",
      "34                     Original Herbivore           40.0          60.0   \n",
      "35                   Pacifico Charbroiled           48.0          52.0   \n",
      "36                               Paradise            0.0           4.0   \n",
      "37                            Pepe's Taco            0.0           0.0   \n",
      "38                                  Perro           76.0         196.0   \n",
      "39                           Philly Jay's           60.0          48.0   \n",
      "40                        Pinch of Flavor          152.0         144.0   \n",
      "41                       Poutine Brothers           92.0          80.0   \n",
      "42                               Salpicon          284.0          48.0   \n",
      "43                           Savage Tacos           64.0          44.0   \n",
      "44                          Smile Hot Dog          100.0         120.0   \n",
      "45                      Something Good LA            0.0           0.0   \n",
      "46                           StopBye Café          112.0         152.0   \n",
      "47                          Stout Burgers            0.0           0.0   \n",
      "48                          Sugo Italiano           64.0          48.0   \n",
      "49                       Sweets on Wheels           48.0           4.0   \n",
      "50                Taste Collective Burger            0.0           0.0   \n",
      "51                        Thai Mex Cocina           36.0          56.0   \n",
      "52                            Tokyo Style           64.0          88.0   \n",
      "53                              Trapiyaki            0.0           0.0   \n",
      "54                             Uncle Al's          100.0          80.0   \n",
      "55                          Venice Gelato            8.0           4.0   \n",
      "56                                   Wafl           96.0          76.0   \n",
      "57                           White Rabbit            0.0           0.0   \n",
      "58                                  Yalla           52.0          64.0   \n",
      "59                             Yuna's Bob           92.0         100.0   \n",
      "\n",
      "    9:00pm - 12am  10:30am - 3pm  5:00pm - 8pm  8:00pm - 11pm  10:30am - 2pm  \\\n",
      "0            42.0           36.0          42.0            9.0            0.0   \n",
      "1            24.0            0.0           0.0            0.0            0.0   \n",
      "2             0.0            0.0           3.0            0.0            0.0   \n",
      "3            45.0           36.0          66.0           36.0            0.0   \n",
      "4             6.0           54.0          45.0            0.0            0.0   \n",
      "5             0.0           36.0          24.0            9.0            3.5   \n",
      "6            69.0           13.5          21.0            0.0            3.5   \n",
      "7           168.0            0.0           0.0            0.0            0.0   \n",
      "8            57.0            0.0           3.0            0.0            0.0   \n",
      "9             0.0            4.5           3.0            3.0            0.0   \n",
      "10           24.0            0.0           6.0            0.0            0.0   \n",
      "11           78.0           36.0          42.0           42.0            0.0   \n",
      "12           75.0           31.5          30.0           18.0            0.0   \n",
      "13          210.0            0.0           3.0           36.0            0.0   \n",
      "14           12.0           13.5           9.0            6.0            0.0   \n",
      "15            0.0            0.0           0.0            3.0            0.0   \n",
      "16           36.0            0.0           0.0            0.0            0.0   \n",
      "17           69.0            0.0           0.0            0.0            0.0   \n",
      "18            0.0           13.5          18.0            9.0            3.5   \n",
      "19           66.0           90.0          78.0           24.0            3.5   \n",
      "20            0.0            0.0           0.0           18.0            0.0   \n",
      "21            6.0            0.0           0.0            0.0            0.0   \n",
      "22            0.0            9.0           6.0            9.0            0.0   \n",
      "23           42.0            0.0           0.0            0.0            0.0   \n",
      "24            0.0            0.0           0.0            0.0            0.0   \n",
      "25            0.0            0.0           3.0            0.0            3.5   \n",
      "26           87.0            0.0           0.0            0.0            0.0   \n",
      "27           30.0          252.0           6.0            0.0            3.5   \n",
      "28            0.0            4.5           6.0            0.0            3.5   \n",
      "29            0.0           31.5          57.0           24.0            0.0   \n",
      "30            0.0            0.0           3.0            9.0            0.0   \n",
      "31            0.0            0.0           3.0            0.0            0.0   \n",
      "32            0.0           13.5           6.0            6.0            0.0   \n",
      "33            0.0            0.0           6.0            0.0            0.0   \n",
      "34           42.0           45.0          63.0           18.0            0.0   \n",
      "35           42.0           49.5          33.0           24.0            0.0   \n",
      "36          129.0            0.0           0.0            6.0            0.0   \n",
      "37            0.0            4.5           6.0            0.0            3.5   \n",
      "38          141.0            0.0          15.0           12.0            0.0   \n",
      "39           36.0           18.0          45.0           18.0            0.0   \n",
      "40           84.0           76.5          66.0           51.0            0.0   \n",
      "41           51.0           49.5          33.0           18.0            0.0   \n",
      "42            9.0            0.0           0.0            0.0            0.0   \n",
      "43           12.0           18.0          24.0            9.0            0.0   \n",
      "44           57.0            0.0           0.0            0.0            0.0   \n",
      "45            0.0            4.5          24.0           15.0            0.0   \n",
      "46            9.0           27.0          36.0           15.0            0.0   \n",
      "47            0.0           13.5          12.0            9.0            0.0   \n",
      "48            3.0            0.0           0.0            0.0            0.0   \n",
      "49           66.0            0.0           0.0            0.0            0.0   \n",
      "50            0.0            9.0           3.0            3.0            0.0   \n",
      "51            9.0            0.0           0.0            0.0            0.0   \n",
      "52           66.0           40.5          42.0           12.0            0.0   \n",
      "53            0.0           40.5          51.0           24.0            0.0   \n",
      "54           33.0           18.0          18.0           15.0            0.0   \n",
      "55           39.0            0.0           0.0            6.0            0.0   \n",
      "56           66.0           81.0          69.0           81.0            0.0   \n",
      "57            0.0            0.0           9.0            3.0            0.0   \n",
      "58           15.0           13.5           3.0            0.0            0.0   \n",
      "59           12.0            0.0           3.0            0.0            0.0   \n",
      "\n",
      "    Total Sum  \n",
      "0       393.0  \n",
      "1       212.0  \n",
      "2         3.0  \n",
      "3       259.0  \n",
      "4       165.0  \n",
      "5       144.5  \n",
      "6       247.0  \n",
      "7       180.0  \n",
      "8       224.0  \n",
      "9        30.5  \n",
      "10      110.0  \n",
      "11      434.0  \n",
      "12      366.5  \n",
      "13      277.0  \n",
      "14       48.5  \n",
      "15        3.0  \n",
      "16      276.0  \n",
      "17      161.0  \n",
      "18      220.0  \n",
      "19      429.5  \n",
      "20       18.0  \n",
      "21      142.0  \n",
      "22       24.0  \n",
      "23      190.0  \n",
      "24       32.0  \n",
      "25        6.5  \n",
      "26      255.0  \n",
      "27      371.5  \n",
      "28       14.0  \n",
      "29      112.5  \n",
      "30       12.0  \n",
      "31        3.0  \n",
      "32       25.5  \n",
      "33        6.0  \n",
      "34      268.0  \n",
      "35      248.5  \n",
      "36      139.0  \n",
      "37       14.0  \n",
      "38      440.0  \n",
      "39      225.0  \n",
      "40      573.5  \n",
      "41      323.5  \n",
      "42      341.0  \n",
      "43      171.0  \n",
      "44      277.0  \n",
      "45       43.5  \n",
      "46      351.0  \n",
      "47       34.5  \n",
      "48      115.0  \n",
      "49      118.0  \n",
      "50       15.0  \n",
      "51      101.0  \n",
      "52      312.5  \n",
      "53      115.5  \n",
      "54      264.0  \n",
      "55       57.0  \n",
      "56      469.0  \n",
      "57       12.0  \n",
      "58      147.5  \n",
      "59      207.0  \n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "#counts_df = pd.read_csv(\"counts.csv\")\n",
    "\n",
    "# Rename the incorrect column name\n",
    "counts_df.rename(columns={\"9:00pm - 12pm\": \"9:00pm - 12am\"}, inplace=True)\n",
    "\n",
    "def calculate_duration(time_range):\n",
    "    start, end = time_range.split(\" - \")\n",
    "    \n",
    "    # Convert to 24-hour format and extract hours\n",
    "    def to_hours(time_str):\n",
    "        time, period = time_str[:-2], time_str[-2:]\n",
    "        hours, minutes = map(int, time.split(\":\")) if \":\" in time else (int(time), 0)\n",
    "        if period == \"pm\" and hours != 12:\n",
    "            hours += 12\n",
    "        if period == \"am\" and hours == 12:\n",
    "            hours = 0\n",
    "        return hours + minutes / 60\n",
    "    \n",
    "    start_hours = to_hours(start)\n",
    "    end_hours = to_hours(end)\n",
    "\n",
    "    # Handle the midnight crossover (e.g., 9:00pm - 12am should be 3 hours)\n",
    "    if end_hours < start_hours:\n",
    "        end_hours += 24  # Adjust end time to correctly calculate the difference\n",
    "    \n",
    "    return end_hours - start_hours\n",
    "\n",
    "counts_df.reset_index(inplace=True) # resetting index\n",
    "\n",
    "# Extract time interval columns (excluding the first column with vendor names)\n",
    "time_columns = counts_df.columns[1:]\n",
    "\n",
    "# Compute durations for each time interval\n",
    "durations = {col: calculate_duration(col) for col in time_columns}\n",
    "\n",
    "# Multiply each column by its respective duration\n",
    "for col in time_columns:\n",
    "    counts_df[col] = counts_df[col] * durations[col]\n",
    "\n",
    "# Add a new column with the sum of each row\n",
    "counts_df[\"Total Sum\"] = counts_df.iloc[:, 1:].sum(axis=1)\n",
    "print(counts_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
